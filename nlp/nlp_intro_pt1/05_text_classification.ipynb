{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "![nlp](https://wrm5sysfkg-flywheel.netdna-ssl.com/wp-content/uploads/2019/01/NLP-Technology-in-Healthcare.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section goals are to understand the machine learning basics, to understand what classification metrics are. We will then look at text feature extraction and use python with Scikit-learn to perform classification on some real data sets. \n",
    "\n",
    "#### Q: What are we doing here?\n",
    "A: To conceptualise what we're doing here we need to understand that it is what is known as _\"supervised learning\"_. An interesting additional text in this area of study is [an Introduction to statistical learning](http://faculty.marshall.usc.edu/gareth-james/ISL/) in which the student can get a better grasp of the mathematics involved in machine learning, largely linear algebra, calculus. \n",
    "\n",
    "#### Q: So, what is machine learning?\n",
    "A: Essentially it's a method of data analysis that automates analytical model building by using algorithms that iteratively learn from the data being processed or worked upon. Machine learning facilitates computers identifying hidden insights in data without being explicitly programmed to do so.  \n",
    "\n",
    "#### Q: OK, What is it used for? \n",
    "A: OK, here goes... Fraud detection, web search results, real time ads on web pages, credit scoring and next best offer, prediction of failure and equipment failure, pricing models, network intrusion detection, recommender engines, customer segmentation, sentiment analysis, churn prediction, pattern and image recognition, spam filtering... Once upon a time they used to say javascript was eating the world, now in late 2020 it's ML that's eating the world. \n",
    "\n",
    "#### Q: So what is supervised learning?\n",
    "A: supervised learning algorithms are rained on what call 'labeled data', that means data where the desired output is known. typically our data in such circumstances is retrospective and has been classified and we're working to get the machine to successfully arrive at conclusion we can cross reference with the real output or result. In automated terms the machine can adjust its weights in an algorithm to tweak it's processing where it can see the prediction is not the same as the known output. The common usage, or scenario where supervised learning is undertaken is for applications where historical data predicts likely suture events. \n",
    "\n",
    "#### Q: So what does the supervised learning process look like?\n",
    "A: It is a multi step process. \n",
    "1. Data Acquisition\n",
    "2. Data cleaning (formatting, vectorization, feature extraction, null cleaning)\n",
    "3. Split between test data and training data becaise you don't want to test your model on data it has already seen and processed. Here is can be anything between 65/35 to 85/15 split ratio. Ultimately the more training data you have the _better_ the result you're likely to get. (loosely speaking) \n",
    "4. Fit and evaluate your model on testing data.\n",
    "5. we repeat steps 3 & 4 until we have a workable result we want to deploy or we abandon as not a good model and look to iterate on corrective steps, starting at point 1 again and improving all steps in pursuit of a better result.\n",
    "\n",
    "Some common terms that may be encountered in the data collection, cleansing and processing steps are: \n",
    "- `Ham Vs Spam` - good Vs bad, etc... \n",
    "- `x_train & x_test, y_train & y_test` - Where data is split between `x,y` as the axes of a graph, the data and the label. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1.0 - Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our process is complete we use performance metrics to evaluate how our model performed. The key classification metrics we will come to understand are:\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "- F1-Score (culmination of recall and precision)\n",
    "\n",
    "Typically, a model can only achieve two results, it was correct with its prediction, or it was wrong. This expands to situations where you have multiple classes. In terms of a real world scenario, imagine a **binary classification** situation where we only have two classes available.\n",
    "\n",
    "Keep in mind there are a few steps involved to convert the raw text data into a format that an ML model can understand. Vectorization is a process where we pass raw text from the `x_test` through the process to become a vectorized version of `x_test`.\n",
    "\n",
    "#### Q: How do we setup vectorization?\n",
    "A: We setup this vectorization process in the pipeline and there are many ways of transforming the raw text into numerical information. \n",
    "\n",
    "Once complete we run the model on the test data and derive our classifications. At the end we have a count of both correct and incorrect matches. The key is to remember that in the real world **_not all incorrect or correct matches hold equal value_**. This is why there often different classification metrics, a single metric wont tell the real,or whole story. so let's look at each and what it is for.\n",
    "\n",
    "#### Accuracy\n",
    "Accuracy is the number of correct classifications or predictions divided by the number of predictions. Accuracy is useful when you have a well balanced set of data with a balanced set of actual classifications. Accuracy is a poor choice when the data is heavily weighted towards 1 classification type. In our `ham vs spam` example a set of 95 ham vs 5 spam would make an accuracy metric a bad choice because the test is not balanced, where as a 50/50 split would be the most balanced and therefore would make accuracy a good metric here. \n",
    "\n",
    "Where balance is compromised making accuracy a poor choice `recall` and `precision` make for useful additions to our metric to complete the story. \n",
    "\n",
    "#### Recall\n",
    "The ability of a model to find **_all_** the relevant cases in a dataset. The precise definition of recall is _\"number of true positives divided by the number of true positives plus the number of false negatives\"_.\n",
    "\n",
    "#### Precision\n",
    "Ability of a classification model to identify **_only_** the relevant data points. Precision is defined as _\"the number of true positives divided by the number of true positives plus the number of false positives\"_.\n",
    "\n",
    "**Note:** often you have a trade-off between recall and precision. Recall expresses the ability to find all relevant instances in a dataset. Precision expresses the proportion of the data points our model says was relevant which were _actually_ relevant.\n",
    "\n",
    "#### F1-Score\n",
    "Combination of recall and precision deemed to be the _optimal blend_.\n",
    "\n",
    "$F_1 = 2 * \\frac{{precision} \\cdot {recall}}{precision + recall}$\n",
    "\n",
    "This is called the **harmonic mean** as it takes both metric into account. We use this instead of an average because it punishes extreme values. A classifier with a precision of 1.0 and a recall of 0.0 has a simple average of 0.5 but an F1-score of 0.0 \n",
    "\n",
    "**Step 1:** $F_1 = 2 * \\frac{1 \\cdot 0}{1 + 0}$ \n",
    "\n",
    "**Step 2:** $F_1 = 2 * \\frac{0}{1}$ \n",
    "\n",
    "**Step 3:** $F_1 = 2 * 0 = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.0 The Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within a classification problem there are two categories:\n",
    "- True condition\n",
    "- predicted condition\n",
    "\n",
    "That means at the end of the testing phase there are 4 possible groups:\n",
    "- Output was `True` and classified as `True`\n",
    "- Output was `True` and classified as `False`\n",
    "- Output was `False` and classified as `True`\n",
    "- Output was `False` and classified as `False`\n",
    "\n",
    "**Note:** It is important to remember that there are many fancy stats that can be obtained from a confusion matrix but they are all fundamentally ways of comparing predicted Vs true values. What is determined as `good metrics` will often depend on the specific situation to be evaluated.\n",
    "\n",
    "[Wikipedia for Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "![](https://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i2.wp.com/softwareengineeringdaily.com/wp-content/uploads/2016/09/scikit-learn-logo.png)\n",
    "\n",
    "# 5.3.0 - Scikit-learn Introduction and overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Every algorithm is exposed in scikit-learn via an Estimator. \n",
    "- Estimator is just another word for Model. \n",
    "- All Estimators take parameterisation, whilst having generally suitable defaults in place. \n",
    "- Fitting a model, is also 'training' a model.\n",
    "- It is critical to split the data between train and test sets. \n",
    "- Scikit-learn, or 'sklearn' comes with a `train_test_split` functionality. \n",
    "- Absolute datasize in sklearn is between 0-1, of you want 25% of your data split between test and training then test_size parameter should be set to 0.25\n",
    "- To predict you can use the `model.predict(test_data_set)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./resources/smsspamcollection.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing specific df columns\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label'] == 'ham']['length'], bins=bins, alpha=0.6)\n",
    "plt.hist(df[df['label'] == 'spam']['length'], bins=bins, alpha=0.6)\n",
    "plt.legend(('ham', 'spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label'] == 'ham']['punct'], bins=bins, alpha=0.6)\n",
    "plt.hist(df[df['label'] == 'spam']['punct'], bins=bins, alpha=0.6)\n",
    "plt.legend(('ham', 'spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = feature data \n",
    "# y = label\n",
    "\n",
    "x = df[['length', 'punct']]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lrmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245     ham\n",
       "944      ham\n",
       "1044     ham\n",
       "2484     ham\n",
       "812      ham\n",
       "        ... \n",
       "2505     ham\n",
       "2525    spam\n",
       "4975     ham\n",
       "650     spam\n",
       "4463     ham\n",
       "Name: label, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true values \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ham</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ham</th>\n",
       "      <td>1404</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spam</th>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ham  Spam\n",
       "Ham   1404    44\n",
       "Spam   219     5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pandas dataframe with the conf matrix\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test, preds), index=['Ham', 'Spam'], columns=['Ham', 'Spam'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "    accuracy                           0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427033492822966\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying an alternate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1438   10]\n",
      " [ 224    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nbmodel = MultinomialNB()\n",
    "nbmodel.fit(x_train, y_train)\n",
    "preds = nbmodel.predict(x_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92      1448\n",
      "        spam       0.00      0.00      0.00       224\n",
      "\n",
      "    accuracy                           0.86      1672\n",
      "   macro avg       0.43      0.50      0.46      1672\n",
      "weighted avg       0.75      0.86      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying other models and support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1420   28]\n",
      " [ 186   38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svcmodel = SVC()\n",
    "svcmodel.fit(x_train, y_train)\n",
    "preds = svcmodel.predict(x_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.88      0.98      0.93      1448\n",
      "        spam       0.58      0.17      0.26       224\n",
      "\n",
      "    accuracy                           0.87      1672\n",
      "   macro avg       0.73      0.58      0.60      1672\n",
      "weighted avg       0.84      0.87      0.84      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8720095693779905\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4.0 - Text Feature Extraction Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of ML algorithms can't take in raw text. Instead we need to perform an `extraction` from the raw text in order to pass numerical features to the ML algorithm. \n",
    "\n",
    "- Counter Vectorization\n",
    "- Term Frequency\n",
    "- Inverse document frequency\n",
    "\n",
    "#### Q: What is Counter Vectorization?\n",
    "A: We can use sklearn lib to import `CountVectorization` from `sklearn.feature_extraction.text`. This counts the occurrences of all the unique words. This process treats each word as a feature thus creating a DTM `Document Term Matrix`. For a large set of documents, known as a corpus, we will have a large matrix largely populated with zeros.\n",
    "\n",
    "#### Q: What is a TfidfVecorizer?\n",
    "A: An alternative to CountVectorizer, it also creates a DTM from our messages. However, instead of filling with token counts it calculates the term-frequency-inverse for each word. So the TF, or term frequency is really just a count of how many times that word appears in a document. \n",
    "\n",
    "The inverse model handles the stop-words that appear so frequently that they disrupt the effectiveness of other models by muddying the weighting. The inverse model diminishes the weight of very frequent words and amplifies that of more rare words.\n",
    "\n",
    "The logarithmically scaled inverse fraction of the documents that contain the word _(number of documents / number of documents containing the term, and then the log of that quotient)_\n",
    "\n",
    "- TF-IDF = term frequency * (1 / document frequency)\n",
    "- TF-IDF = term frequency * inverse document frequency\n",
    "\n",
    "$tfidf(t, d, D) = tf(t, d) \\cdot idf(t, D)$\n",
    "\n",
    "$idf(t, D) = \\log \\frac{N}{|{d \\in D : t \\in d }|}$\n",
    "\n",
    "Fortunately for us, sklearn has these calculations available via simple API calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\"Hey, let's go to the game today!\", \"Call your sister.\", \"want to go walk your dogs?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "dtm = vec.fit_transform(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5.0 - Text Feature Extraction Practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./resources/smsspamcollection.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nulls \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check values \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df['message']\n",
    "y = df['label']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 - Step-by-Step walkthrough\n",
    "\n",
    "- create a CountVectorizer \n",
    "- perform a `fit_transform` to get the_counts\n",
    "- create a transformer\n",
    "- transformer.fit_transform(the_counts)\n",
    "- create a tfidVectorizer\n",
    "- tfidVectorizer(transformer.fit_transform(the_counts))\n",
    "- create the SVC classifier\n",
    "- perform te SCV fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the raw text and vectorize it\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform x with the vectorizer. \n",
    "# fit vectorizer to the data to buid a vocabulary and count the number \n",
    "# of words as separate steps.\n",
    "\n",
    "# Granular steps\n",
    "# cvec.fit(x_train)\n",
    "# x_train_counts = cvec.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform original -> vector (fit transform)\n",
    "\n",
    "# convenience method that performs the steps above in one call\n",
    "\n",
    "x_train_counts = cvec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3733x7082 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 49992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see that numpy is smart enough here to take efficiency management\n",
    "# steps with the output. This optimises machine resources and saves\n",
    "# wastig memory on an artefact it would not be useful to show\n",
    "\n",
    "x_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf transformer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer \n",
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a fit transform on the counts \n",
    "# that we obtained above \n",
    "x_train_tfidf = tfidf.fit_transform(x_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vectorizer \n",
    "\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the classifier \n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "clf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 - Create a Pipeline to perform the process\n",
    "\n",
    "Now we want to use the scikit-learn library efficient walkthrough coupled with our pipeline that we have created in order to achieve efficiency and minimise the code required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat everything in a pipelne step \n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short pipeline example that demonstrates \n",
    "# vectorization and classifi\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show updated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykit",
   "language": "python",
   "name": "pykit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
