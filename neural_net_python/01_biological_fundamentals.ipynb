{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological Fundamentals\n",
    "\n",
    "#### Leading points\n",
    "- Scientific study estimates the amount of neurons in an adult brain to be more than 100 billion. \n",
    "- All these neurons are connected and interconnected. \n",
    "- Information flows between the neurons via these information-link connections which go to explaining human capabilities such as walking, reading, typing, understanding, questioning and so on. \n",
    "- These connections control communications, emotions, creativity etc.. \n",
    "\n",
    "This leads to defining a neural network as `a network of neurons that exchange information`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic components of a Neuron\n",
    "\n",
    "- Dendrites\n",
    "    - receive data from other neurons.\n",
    "- Cell body \n",
    "    - processes the data received in an information transfer. The information is the flow of electrical signals and its transfer is called `synapse`. The `synapse` is the journey from the Dendrites to the point of continued transfer from the Axon via the terminals. After the process of `synapse` biological chemicals enter the Dendrites for the purpose of increasing/decreasing the electrical potential of the cell body.\n",
    "    - The electrical flow in a biological neuron is what gives the potential of the cell which will lead to decision making. \n",
    "    - Therefore, we can say that new connections (and new learning) is formed from these potentials.  \n",
    "- Axon\n",
    "    - transmits signals to other neurons using the Axon terminals.\n",
    "- Axon terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Artificial Neuron\n",
    "\n",
    "The artificial neuron mimics the biological structure. We have the equivalence of `Dendrites`, `Cell bodies` & `Axom terminals` in the artificial setting. \n",
    "\n",
    "- It is entirely possible for an an indefinite amount of inputs and outputs to an artificial neuron. \n",
    "- The inputs are information, data or datums from environment.\n",
    "- The outputs are the final response of the perceptron such as a decision or prediction.\n",
    "\n",
    "#### Example consideration\n",
    "In order to predict a persons salary we might reasonably expect that to be based on two key attributes:\n",
    "- age\n",
    "- Educational Background\n",
    "The perceptron receives the age as an input to the equivalent of the Dendrites, this will typically be represented by a figure, followed by another number for years of study or numerical indicator of depth of education. This is processed and the output will also be a number that indicates/predicts the salary of the profile based on the inputs.\n",
    "\n",
    "There is a `black box` around the `Cell body` of a neuron because it is not that easy to interpret what happens during this process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important disclaimers**\n",
    "- it is not known truly how the human brain works but there are significant insights which form the opinions on which the work of all artificial neural technology is based. \n",
    "- Artificial neural networks are merely an abstraction of what is known/accepted in this field of study. \n",
    "- They are nothing more than a simulation of a brain, or thought process.\n",
    "- We can depict the artificial neuron as follows: \n",
    "![neuron](https://www.researchgate.net/profile/Mike_Riley/publication/299490278/figure/fig1/AS:626481235517442@1526376174991/Artificial-Neuron-Structure.png)\n",
    "\n",
    "#### key takeaways:\n",
    "- Inputs are of an indeterminate number\n",
    "- each input is weighted, weighting dictates importance/credence factors.\n",
    "- We then have the `sum function` and the `activation function` which equates to the `black box` of above. \n",
    "- It works on the basis of $sum = \\sum\\limits_{i=1}^n xi \\cdot wi$\n",
    "- In an example with 4 inputs this means that what is passed to the sum function would be: $x1 \\cdot w1 + x2 \\cdot w2 + x3 \\cdot w3 + x4 \\cdot w4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron\n",
    "\n",
    "The Perceptron is the combination of the inputs & weights passed to the sum function and the activation function. Above we seen that the sum function has the job of taking each input & multiplying it by the associated weight for that input, adding to the results of other $input \\cdot weight$ calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example case 1\n",
    "If we take a two-input example case for age and education, we could have the following attributes:\n",
    "- age: input=35, weight=0.8\n",
    "- education: input=25, weight=0.1\n",
    "\n",
    "#### First simplification\n",
    "The sum function is now: \n",
    "- $sum = (35 \\cdot 0.8) + (25 \\cdot 0.1)$\n",
    "\n",
    "#### Second simplification\n",
    "The first simplification is: \n",
    "- $sum = (28) + (2.5)$ = $30.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "We can now apply the activation function. This indicates whether a neuron was `fired or not` or `activated or not`. This `synapse` will change the electrical potential in the biological example but we have no electrical signal in the artificial example so how we represent that in the simplest terms is a `step function` that makes a simple fork decision:\n",
    "- Greater or equal to 1 = 1 (neuron activated)\n",
    "- Otherwise = 0\n",
    "\n",
    "In the sample above we have: \n",
    "$(35 \\cdot 0.8) + (25 \\cdot 0.1) \\sum f = 1$\n",
    "\n",
    "In this simple example that firing is decision tree and in our example analysis we can say a: \n",
    "- `1` indicates the person might receive a salary increase. \n",
    "- `0` indicates not. \n",
    "\n",
    "You can see in this example our step/activation function is trivial and in real cases we will have a more complex set of decision forks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example case 2\n",
    "For example case two we will the same structure of a two-input perceptron, we will re-use the age & education factors and only change the weights. We now have the following attributes:\n",
    "- age: input=35, weight=-0.8\n",
    "- education: input=25, weight 0.1\n",
    "\n",
    "#### Simplification 1\n",
    "$sum = (35 \\cdot -0.8) = (25 \\cdot 0.1) = (-28 +2.5) = -25.5$\n",
    "\n",
    "#### Summary\n",
    "Meaning that under the same `step function` decision fork the nueron will have the negative value and be aggregated to a zero (unfired) in our case and indicate that person may not receive a salary increase in the current scoring. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We can see that the graph of our step function has only a window between zero and one. At both zero and one we have straight lines of cut-off meaning the values above or below do not matter. Depending on the application we can define the step function thresholds in order to create categorised returns. \n",
    "\n",
    "#### Complimentary theoretical definitions of a Perceptron\n",
    "- Positive weight indicates an exciting synapse (electrical increase of the cell body, or greater likelihood of activation)\n",
    "- Negative weight indicates an inhibitory synpase. Lessening the chances of activation.\n",
    "- Weights are considered synapses\n",
    "- Weights amplify or reduce the input signal. _(see differentiation between value in `ex1 & ex2` purely based on weighting)_\n",
    "- The knowledge of a neural network _is_ the weights. _(The goal of a neural net is to learn the best set of weights that fits a given dataset)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accordance to the lessons above we need to define and implement the step and sum functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum function. \n",
    "def sum(inputs, weights):\n",
    "    # checks length f params is good\n",
    "    if len(inputs) == len(weights):\n",
    "        s = 0\n",
    "        for i in range(2):\n",
    "            s += inputs[i] * weights[i]\n",
    "        return s\n",
    "    else:\n",
    "        print(f\"ERROR: inputs length={len(inputs)} : weights length={len(weights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step function\n",
    "def step_function(sum):\n",
    "    if sum >= 1 : return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the input scores for \n",
    "# age, education respectively \n",
    "\n",
    "inputs = [35,25]\n",
    "\n",
    "# create a list of the weightings to \n",
    "# apply to each input \n",
    "\n",
    "weights = [0.8, 0.1]\n",
    "\n",
    "# call the step function passing in the result\n",
    "# of the sum function call that takes in the \n",
    "# lists for inputs and weights. \n",
    "\n",
    "step_function(sum(inputs, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example here we return a `1`. This means the neuron `is fired`. In the definition of our example the employee would have qualified for a salary increase based on the decision forks implemented and the parameters passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution example 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep same params for age, education.\n",
    "inputs = [35,25]\n",
    "\n",
    "# change the weights to a negative on age\n",
    "weights = [-0.8, 0.1]\n",
    "\n",
    "# call the step with updated weights.\n",
    "step_function(sum(inputs, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are returning a `0`. The neuron is `not fired`. In this case the employee would not qualify for a salary increase based on the decision forks and parameters passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykit",
   "language": "python",
   "name": "pykit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
