{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multi layered perceptron](https://www.researchgate.net/profile/William_Guo5/publication/274919146/figure/fig4/AS:324198795890704@1454306424966/Three-layer-multilayer-perceptron-MLP-neural-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multi-Layered Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction to Multi-layer networks\n",
    "2. Activation functions (sigmoids)\n",
    "3. Sigmoid function implementation\n",
    "4. Error Functions\n",
    "5. Gradient Descent\n",
    "6. Backpropagation\n",
    "7. Implementation of multi-layer Perceptron with Python & numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Multi-layer networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the depiction at the top of the workbook the main concepts of a multilayer perceptron. \n",
    "- The idea of a hidden layer. \n",
    "- The confirmation that each neuron of that layer should its own: \n",
    "    - sum function \n",
    "    - activation function. \n",
    "- We see that for each input and weight, there is a connection to each neuron in the hidden layer. This means that a great many individual connection lines may be seen. \n",
    "- We see that each neuron in the hidden layer is connected to the last neuron in the output layer and passes the weights along these connections. \n",
    "- The output layer neuron will have a sum function & activation function. This leads to a final output from our networks evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions (Introducing sigmoids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have different types of activation function. In the single layer perceptron study we seen what is called the step function: \n",
    "- `Step functions` : can have values of zero or 1, ie values are stepped. \n",
    "\n",
    "We can also have sigmoid functions where values are in a range. \n",
    "- `Sigmoid functions` : can have a value in the **_range of 0 to 1_**, the function has the ability to touch all the points between 0 & 1. To get the value we can apply the following equation: $y = \\frac{1}{1 + e^{-x}}$. This works by determining where on the line a value belongs.\n",
    "    - if `x` is high, the value lies closer to, or equal to 1. \n",
    "    - if `x` is low , the value lies closer to, or equal to 0. \n",
    "    \n",
    "If we need to return negative values we can use the `hyperbolic tangent function`:\n",
    "- $y = \\frac{e^{x} - e^{-x} }{e^{x} + e^{-x}}$\n",
    "- evaluating the equation asks to replace the `x` with the value under evaluation and the return will be graded between `-1` & `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden layer activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of multi-layer Perceptron with Python & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykit",
   "language": "python",
   "name": "pykit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
