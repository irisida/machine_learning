{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical flow is the pattern of apparent motion of image objects betwen two consecutive frames caused by the movement of the object or of the camera.\n",
    "\n",
    "#### Assumptions are: \n",
    "- pixel intesities of an object do not change between consecutive frames. \n",
    "- neighbouring pixels have a similar motion. \n",
    "\n",
    "#### Usage caveats:\n",
    "- The Lucas-Kanade operates on a sparse feature set. \n",
    "- This meansit *only* takes care and tracks the points it was told to track. \n",
    "- optical flow methods in openCV take in a given set of points and a frame. \n",
    "- it will look for those points in the next frame. \n",
    "- The user supplies the points to be tracked. \n",
    "- we pass the points and the previous frame to the Lucas-Kanade function.\n",
    "\n",
    "\n",
    "If you want to track all the points in a video the `Gunner Farneback` algorithm may be amore appropriate choice to calculate dense optical flow. This calculates all the points in a video, colouring them black where no flow is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas Kanade method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'maxCorners' number of best quality point to detect\n",
    "# 'qualityLevel' \n",
    "# 'minDistance'\n",
    "# 'blockSize'\n",
    "# all used for corner detection\n",
    "corner_track_params = dict(maxCorners = 10, qualityLevel=0.3, minDistance=7, blockSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for the Lucas Kanade function to be called.\n",
    "# 'winSize' is a trade off between small (more sensitive to \n",
    "# noise, less to fast motion) and large (less sensitivity, \n",
    "# but better for fast motion)\n",
    "# 'maxLevel' is related to the image pyramid, multi-layer, \n",
    "# multi-resolution imaging.\n",
    "# EPS vs COUNT is about speed vs accuracy\n",
    "lk_params = dict(winSize=(200,200), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/video/src/lkpyramid.cpp:1244: error: (-215:Assertion failed) (npoints = prevPtsMat.checkVector(2, 5, true)) >= 0 in function 'calc'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5bfb0984cb67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# calc the optical flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnextPts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowPyrLK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevPts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlk_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mgood_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextPts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /opt/concourse/worker/volumes/live/9523d527-1b9e-48e0-7ed0-a36adde286f0/volume/opencv-suite_1535558719691/work/modules/video/src/lkpyramid.cpp:1244: error: (-215:Assertion failed) (npoints = prevPtsMat.checkVector(2, 5, true)) >= 0 in function 'calc'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# declare the points \n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask=None, **corner_track_params)\n",
    "\n",
    "# use mask for visualising / drawing on \n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # calc the optical flow\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    \n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "    \n",
    "    for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "        x_new, y_new = new.ravel()\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "        \n",
    "        mask = cv2.line(mask, (x_new, y_new), (x_prev, y_prev), (0, 255, 0), thickness=3)\n",
    "        \n",
    "        frame = cv2.circle(frame, (x_new, y_new), 8, (0,0, 255), thickness = 2)\n",
    "        \n",
    "    \n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow('Tracking', img)\n",
    "\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvkit",
   "language": "python",
   "name": "cvkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
