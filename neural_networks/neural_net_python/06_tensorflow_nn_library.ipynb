{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow\n",
    "\n",
    "Support many types of neural networks such as CNNs & RNNs. It is the primary ML library at Google for complex and large scale ML projects. It also supports GPU processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class: 5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQgklEQVR4nO3de4xc5X3G8e9TA4owxuBQjEUgjqllCog4lTENuCWImptAxkCiOKFyBcJUxRIR1CpyqwZamaJwaYMCxI6A4JY6UAHFoKSYYsA0tBaLMTdTgoNMYrPFEHvxhavtX/+YY7QxO+/szpyZM973+UirmTm/OXN+DH72vDPnnH0VEZjZ8Pc7VTdgZp3hsJtlwmE3y4TDbpYJh90sEw67WSYc9gxIukbSv1Tdh1XLYR8mJH1LUo+kbZJ6Jf1M0rSq+wKQtE7SB0Vv2yQtq7qnHDnsw4CkK4F/Aq4DxgJHArcBMypsa0/nRsQBxc/pVTeTI4d9LydpNPB3wOUR8UBEbI+ITyLi4YiYV2edf5P0f5Lek7RC0rH9amdLWiNpq6QNkv6yWH6IpEck9UnaJOlpSf73sxfx/6y931eBzwEPDmGdnwETgUOBVcA9/Wp3AJdFxCjgOGB5sfwqYD3wu9RGD/OBAJB0m6TbGmzzHknvSFom6ctD6NVKsk/VDVjLPg+8GxE7BrtCRNy5+76ka4DNkkZHxHvAJ8Axkl6IiM3A5uKpnwDjgC9GxFrg6X6v9xcNNvltar9UBFwBPCrp6IjoG2zP1jrv2fd+vwEOkTSoX9ySRki6XtIvJW0B1hWlQ4rbC4CzgTclPSXpq8XyG4C1wDJJb0i6erANRsTPI+KDiHg/Iv4B6AP+aLDrWzkc9r3ffwMfAucN8vnfovbF3Z8Ao4HxxXIBRMSzETGD2hD/34H7iuVbI+KqiJgAnAtcKem0JnuO3duzznHY93LF0PtvgVslnSdpf0n7SjpL0vcGWGUU8BG1EcH+1L7BB0DSfpK+XQzpPwG2ADuL2jmSfk+S+i3f2ag/SUdKOrl47c9JmkdtFPHz1v7Lbagc9mEgIm4GrgT+BngH+DUwl9qeeU+LgTeBDcAa4H/2qP8psK4Y4v85cFGxfCLwn8A2aqOJ2yLiSQBJP5T0wzrtjQJup/bZfwNwJnBWRPxmqP+d1hr5j1eY5cF7drNMOOxmmXDYzTLhsJtloqNn0Enyt4FmbRYRA57D0NKeXdKZkl6TtHYoZ1SZWec1fehN0gjgF8B0ahdIPAvMiog1iXW8Zzdrs3bs2acCayPijYj4GPgJ3XX9tJn100rYD6d2ptZu64tlv0XSnOIvqPS0sC0za1ErX9ANNFT4zDA9IhYBi8DDeLMqtbJnXw8c0e/xF4C3WmvHzNqllbA/C0yU9CVJ+wHfBJaW05aZla3pYXxE7JA0F3gUGAHcGRGvlNaZmZWqo1e9+TO7Wfu15aQaM9t7OOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y0TTUzbb3mHEiBHJ+ujRo9u6/blz59at7b///sl1J02alKxffvnlyfqNN95YtzZr1qzkuh9++GGyfv311yfr1157bbJehZbCLmkdsBXYCeyIiCllNGVm5Stjz35qRLxbwuuYWRv5M7tZJloNewDLJD0nac5AT5A0R1KPpJ4Wt2VmLWh1GH9yRLwl6VDgMUn/GxEr+j8hIhYBiwAkRYvbM7MmtbRnj4i3ituNwIPA1DKaMrPyNR12SSMljdp9HzgdeLmsxsysXK0M48cCD0ra/Tr/GhH/UUpXw8yRRx6ZrO+3337J+kknnZSsT5s2rW7toIMOSq57wQUXJOtVWr9+fbJ+yy23JOszZ86sW9u6dWty3RdeeCFZf+qpp5L1btR02CPiDeDLJfZiZm3kQ29mmXDYzTLhsJtlwmE3y4TDbpYJRXTupLbhegbd5MmTk/Xly5cn6+2+zLRb7dq1K1m/+OKLk/Vt27Y1ve3e3t5kffPmzcn6a6+91vS22y0iNNBy79nNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0z4OHsJxowZk6yvXLkyWZ8wYUKZ7ZSqUe99fX3J+qmnnlq39vHHHyfXzfX8g1b5OLtZ5hx2s0w47GaZcNjNMuGwm2XCYTfLhMNulglP2VyCTZs2Jevz5s1L1s8555xk/fnnn0/WG/1J5ZTVq1cn69OnT0/Wt2/fnqwfe+yxdWtXXHFFcl0rl/fsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmfD17FzjwwAOT9UbTCy9cuLBu7ZJLLkmue9FFFyXrS5YsSdat+zR9PbukOyVtlPRyv2VjJD0m6fXi9uAymzWz8g1mGP9j4Mw9ll0NPB4RE4HHi8dm1sUahj0iVgB7ng86A7i7uH83cF65bZlZ2Zo9N35sRPQCRESvpEPrPVHSHGBOk9sxs5K0/UKYiFgELAJ/QWdWpWYPvb0taRxAcbuxvJbMrB2aDftSYHZxfzbwUDntmFm7NBzGS1oCfA04RNJ64LvA9cB9ki4BfgV8vZ1NDndbtmxpaf333nuv6XUvvfTSZP3ee+9N1hvNsW7do2HYI2JWndJpJfdiZm3k02XNMuGwm2XCYTfLhMNulgmH3SwTvsR1GBg5cmTd2sMPP5xc95RTTknWzzrrrGR92bJlybp1nqdsNsucw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4ePsw9xRRx2VrK9atSpZ7+vrS9afeOKJZL2np6du7dZbb02u28l/m8OJj7ObZc5hN8uEw26WCYfdLBMOu1kmHHazTDjsZpnwcfbMzZw5M1m/6667kvVRo0Y1ve358+cn64sXL07We3t7m972cObj7GaZc9jNMuGwm2XCYTfLhMNulgmH3SwTDrtZJnyc3ZKOO+64ZP3mm29O1k87rfnJfhcuXJisL1iwIFnfsGFD09vemzV9nF3SnZI2Snq537JrJG2QtLr4ObvMZs2sfIMZxv8YOHOA5f8YEZOLn5+W25aZla1h2CNiBbCpA72YWRu18gXdXEkvFsP8g+s9SdIcST2S6v8xMjNru2bDfjtwFDAZ6AVuqvfEiFgUEVMiYkqT2zKzEjQV9oh4OyJ2RsQu4EfA1HLbMrOyNRV2SeP6PZwJvFzvuWbWHRoeZ5e0BPgacAjwNvDd4vFkIIB1wGUR0fDiYh9nH34OOuigZP3cc8+tW2t0rbw04OHiTy1fvjxZnz59erI+XNU7zr7PIFacNcDiO1ruyMw6yqfLmmXCYTfLhMNulgmH3SwTDrtZJnyJq1Xmo48+Stb32Sd9sGjHjh3J+hlnnFG39uSTTybX3Zv5T0mbZc5hN8uEw26WCYfdLBMOu1kmHHazTDjsZploeNWb5e34449P1i+88MJk/YQTTqhba3QcvZE1a9Yk6ytWrGjp9Ycb79nNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0z4OPswN2nSpGR97ty5yfr555+frB922GFD7mmwdu7cmaz39qb/evmuXbvKbGev5z27WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpaJhsfZJR0BLAYOA3YBiyLi+5LGAPcC46lN2/yNiNjcvlbz1ehY9qxZA020W9PoOPr48eObaakUPT09yfqCBQuS9aVLl5bZzrA3mD37DuCqiPh94A+ByyUdA1wNPB4RE4HHi8dm1qUahj0ieiNiVXF/K/AqcDgwA7i7eNrdwHlt6tHMSjCkz+ySxgNfAVYCYyOiF2q/EIBDS+/OzEoz6HPjJR0A3A98JyK2SANOJzXQenOAOc21Z2ZlGdSeXdK+1IJ+T0Q8UCx+W9K4oj4O2DjQuhGxKCKmRMSUMho2s+Y0DLtqu/A7gFcj4uZ+paXA7OL+bOCh8tszs7I0nLJZ0jTgaeAlaofeAOZT+9x+H3Ak8Cvg6xGxqcFrZTll89ixY5P1Y445Jln/wQ9+kKwfffTRQ+6pLCtXrkzWb7jhhrq1hx5K7x98iWpz6k3Z3PAze0T8F1DvA/pprTRlZp3jM+jMMuGwm2XCYTfLhMNulgmH3SwTDrtZJvynpAdpzJgxdWsLFy5Mrjt58uRkfcKECc20VIpnnnkmWb/pppuS9UcffTRZ/+CDD4bck7WH9+xmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSayOc5+4oknJuvz5s1L1qdOnVq3dvjhhzfVU1nef//9urVbbrklue51112XrG/fvr2pnqz7eM9ulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2Uim+PsM2fObKneijVr1iTrjzzySLK+Y8eOZD11zXlfX19yXcuH9+xmmXDYzTLhsJtlwmE3y4TDbpYJh90sEw67WSYGMz/7EcBi4DBq87MviojvS7oGuBR4p3jq/Ij4aYPXynJ+drNOqjc/+2DCPg4YFxGrJI0CngPOA74BbIuIGwfbhMNu1n71wt7wDLqI6AV6i/tbJb0KVPunWcxsyIb0mV3SeOArwMpi0VxJL0q6U9LBddaZI6lHUk9rrZpZKxoO4z99onQA8BSwICIekDQWeBcI4O+pDfUvbvAaHsabtVnTn9kBJO0LPAI8GhE3D1AfDzwSEcc1eB2H3azN6oW94TBekoA7gFf7B7344m63mcDLrTZpZu0zmG/jpwFPAy9RO/QGMB+YBUymNoxfB1xWfJmXei3v2c3arKVhfFkcdrP2a3oYb2bDg8NulgmH3SwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ6PSUze8Cb/Z7fEixrBt1a2/d2he4t2aV2dsX6xU6ej37ZzYu9UTElMoaSOjW3rq1L3BvzepUbx7Gm2XCYTfLRNVhX1Tx9lO6tbdu7QvcW7M60luln9nNrHOq3rObWYc47GaZqCTsks6U9JqktZKurqKHeiStk/SSpNVVz09XzKG3UdLL/ZaNkfSYpNeL2wHn2Kuot2skbSjeu9WSzq6otyMkPSHpVUmvSLqiWF7pe5foqyPvW8c/s0saAfwCmA6sB54FZkXEmo42UoekdcCUiKj8BAxJfwxsAxbvnlpL0veATRFxffGL8uCI+Ksu6e0ahjiNd5t6qzfN+J9R4XtX5vTnzahizz4VWBsRb0TEx8BPgBkV9NH1ImIFsGmPxTOAu4v7d1P7x9JxdXrrChHRGxGrivtbgd3TjFf63iX66ogqwn448Ot+j9fTXfO9B7BM0nOS5lTdzADG7p5mq7g9tOJ+9tRwGu9O2mOa8a5575qZ/rxVVYR9oKlpuun438kR8QfAWcDlxXDVBud24ChqcwD2AjdV2Uwxzfj9wHciYkuVvfQ3QF8ded+qCPt64Ih+j78AvFVBHwOKiLeK243Ag9Q+dnSTt3fPoFvcbqy4n09FxNsRsTMidgE/osL3rphm/H7gnoh4oFhc+Xs3UF+det+qCPuzwERJX5K0H/BNYGkFfXyGpJHFFydIGgmcTvdNRb0UmF3cnw08VGEvv6VbpvGuN804Fb93lU9/HhEd/wHOpvaN/C+Bv66ihzp9TQBeKH5eqbo3YAm1Yd0n1EZElwCfBx4HXi9ux3RRb/9MbWrvF6kFa1xFvU2j9tHwRWB18XN21e9doq+OvG8+XdYsEz6DziwTDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLxP8DahBMj0mQpy8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap=\"gray\")\n",
    "plt.title('Class: ' + str(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the dimension of the image (28 x 28) and to build a neural network capable of working with these we will have to make a transformation to one dimension instead of two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 28 * 28)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can determine that the neural network we must build will have 784 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at a single element of the x_train data\n",
    "# to see it is made up of integers.\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test.reshape(10000, 28 * 28)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** from the output above of assessing the values in x_train[0] that we have large numbers, well, numbers from 0 to 255. Such a range is again not optimal and we should normalise the data to a range of 0-1. This will massively speed up the process. To make the transformation we will have to move from integers to floats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now divide the valie sets by 255 (our previous maximum) to guarantee the maximum is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts numbers to values between 0 & 1. \n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(), x_train.min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we take a look at the `y` data we can see we need to get it categorised. Luckily we can use the np_utils import to help here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the y_train and y_test. \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check a sample where we know the value, index 0 equalled the character 5. \n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to define the netowrk, again using the \n",
    "# number of inputs plus outputs / 2 as a starting point.\n",
    "# shape is 784 -> 397 -> 397 -> 10\n",
    "network = Sequential()\n",
    "\n",
    "# add the first hidden layer specification, here\n",
    "# we selected relu because it is suiitale for deep\n",
    "# learning problems. \n",
    "network.add(Dense(input_shape = (784,), units=397, activation='relu'))\n",
    "\n",
    "# add the 2nd hidden layer specification.\n",
    "# again we have selected relu for the same \n",
    "# reasons as original hidden layer. \n",
    "network.add(Dense(units=397, activation='relu'))\n",
    "\n",
    "# define the output layer. \n",
    "# Here we choose the 'softmax' because we have a \n",
    "# classification problem with mpre than two \n",
    "# choices. \n",
    "network.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the mini batch approach \n",
    "history = network.fit(x_train, y_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do - experienced some library version hell. Come back to fix. \n",
    "# crashing the conda env. repeatable on a new env. Related crashes\n",
    "# identified on google so moving on and revisit on a versions update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykit",
   "language": "python",
   "name": "pykit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
